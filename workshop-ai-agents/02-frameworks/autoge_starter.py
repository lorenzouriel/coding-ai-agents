#!/usr/bin/env python3
"""
Exemplo AutoGen: Colabora√ß√£o de Agentes de IA
Este exemplo demonstra como criar agentes de IA que trabalham juntos
para resolver um problema usando o framework AutoGen.
"""

import autogen
from autogen import AssistantAgent, UserProxyAgent

# Configura√ß√£o para usar Ollama localmente (sem necessidade de chave API!)
config_list = [
    {
        "model": "mistral:latest",  # ou outro modelo Ollama que voc√™ tenha instalado
        "base_url": "http://localhost:11434/v1",  # URL padr√£o do Ollama
        "api_key": "ollama",  # Ollama n√£o precisa de chave real, mas √© obrigat√≥rio informar algo
        "api_type": "openai",  # Usa a API compat√≠vel com OpenAI do Ollama
        "price": [0, 0],  # Pre√ßo fict√≠cio, pois Ollama √© gratuito
    }
]

# Configura√ß√£o do LLM
llm_config = {
    "config_list": config_list,
    "temperature": 0.7,
    "timeout": 120,
}


def advanced_example():
    """
    Exemplo com m√∫ltiplos agentes e chat em grupo
    """
    print("üöÄ Exemplo AutoGen: Resolu√ß√£o de Problemas Multi-Agente")
    print("=" * 60)

    # Criar m√∫ltiplos agentes especializados
    pesquisador = AssistantAgent(
        name="Pesquisador",
        system_message="""Voc√™ √© um especialista em pesquisa. Voc√™ coleta informa√ß√µes e fatos sobre t√≥picos.
        Sempre forne√ßa informa√ß√µes precisas e relevantes sobre o assunto solicitado.""",
        llm_config=llm_config,
    )

    escritor = AssistantAgent(
        name="Escritor",
        system_message="""Voc√™ √© um escritor criativo. Voc√™ pega pesquisas e as transforma em conte√∫do envolvente.
        Escreva de forma clara, interessante e adequada para o p√∫blico-alvo.""",
        llm_config=llm_config,
    )

    critico = AssistantAgent(
        name="Critico",
        system_message="""Voc√™ √© um cr√≠tico que revisa conte√∫do e sugere melhorias.
        Analise o conte√∫do de forma construtiva e forne√ßa sugest√µes espec√≠ficas para melhorar.""",
        llm_config=llm_config,
    )

    usuario_proxy = UserProxyAgent(
        name="Usuario",
        human_input_mode="NEVER",  # Mude para "ALWAYS" se quiser entrada manual
        max_consecutive_auto_reply=2,
        is_termination_msg=lambda x: x.get("content", "").rstrip().endswith("TERMINAR"),
        code_execution_config=False,  # Desabilita execu√ß√£o de c√≥digo para este exemplo
    )

    # Criar um chat em grupo com m√∫ltiplos agentes
    chat_grupo = autogen.GroupChat(
        agents=[usuario_proxy, pesquisador, escritor, critico],
        messages=[],
        max_round=8,  # M√°ximo de 8 rodadas de conversa
    )

    # Criar um gerenciador de chat em grupo
    gerenciador = autogen.GroupChatManager(
        groupchat=chat_grupo,
        llm_config=llm_config,
    )

    # Iniciar a discuss√£o em grupo
    tarefa = """
    Criem uma explica√ß√£o curta e envolvente sobre energias renov√°veis para estudantes do ensino m√©dio.
    
        Pesquisador: Colete fatos importantes sobre energias renov√°veis
        Escritor: Crie uma explica√ß√£o envolvente baseada na pesquisa
        Cr√≠tico: Revise e sugira melhorias
    
    Terminem com 'TERMINAR' quando estiverem satisfeitos com a explica√ß√£o final.
    """

    print("Iniciando a conversa entre os agentes...")
    print("-" * 40)

    # Iniciar o chat
    usuario_proxy.initiate_chat(
        recipient=gerenciador,
        message=tarefa,
    )


if __name__ == "__main__":
    print("ü§ñ Demonstra√ß√£o do Framework AutoGen")
    print("Este exemplo mostra como agentes de IA podem colaborar!")
    print("\nRecursos demonstrados:")
    print("‚úì Cria√ß√£o de agentes de IA especializados")
    print("‚úì Comunica√ß√£o entre agentes")
    print("‚úì Mensagens de sistema baseadas em pap√©is")
    print("‚úì Controle de fluxo de conversa")
    print("‚úì Chat em grupo com m√∫ltiplos agentes")
    print("‚úì Colabora√ß√£o para resolver problemas complexos")
    print("\n" + "=" * 60)

    # Executar o exemplo
    advanced_example()

    print("\nüéâ Demonstra√ß√£o conclu√≠da!")
    print("\nPara executar este exemplo:")
    print("1. Instalar Ollama: https://ollama.ai")
    print("2. Baixar um modelo: ollama pull llama3.1:8b")
    print("3. Iniciar Ollama: ollama serve")
    print("4. Instalar AutoGen: pip install pyautogen")
    print("5. Executar o script!")
    print("\nüí° Vantagens do Ollama:")
    print("   ‚Ä¢ Funciona totalmente offline")
    print("   ‚Ä¢ N√£o precisa de chave API")
    print("   ‚Ä¢ N√£o tem custos de uso")
    print("   ‚Ä¢ Dados ficam no seu computador")
    print("\nüîß Modelos recomendados para come√ßar:")
    print("   ‚Ä¢ llama3.1:8b (mais r√°pido)")
    print("   ‚Ä¢ llama3.1:13b (melhor qualidade)")
    print("   ‚Ä¢ codellama:7b (especializado em c√≥digo)")